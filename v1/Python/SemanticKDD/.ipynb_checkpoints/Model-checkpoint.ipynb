{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Code is from https://github.com/bearpaw/pytorch-pose\n",
    "Hourglass network inserted in the pre-activated Resnet\n",
    "Use lr=0.01 for current version\n",
    "(c) YANG, Wei\n",
    "'''\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "__all__ = ['HourglassNet', 'hg']\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 2\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=True)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=True)\n",
    "        self.bn3 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 2, kernel_size=1, bias=True)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.bn1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv1(out)\n",
    "\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        out = self.bn3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Hourglass(nn.Module):\n",
    "    def __init__(self, block, num_blocks, planes, depth):\n",
    "        super(Hourglass, self).__init__()\n",
    "        self.depth = depth\n",
    "        self.block = block\n",
    "        self.hg = self._make_hour_glass(block, num_blocks, planes, depth)\n",
    "\n",
    "    def _make_residual(self, block, num_blocks, planes):\n",
    "        layers = []\n",
    "        for i in range(0, num_blocks):\n",
    "            layers.append(block(planes*block.expansion, planes))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_hour_glass(self, block, num_blocks, planes, depth):\n",
    "        hg = []\n",
    "        for i in range(depth):\n",
    "            res = []\n",
    "            for j in range(3):\n",
    "                res.append(self._make_residual(block, num_blocks, planes))\n",
    "            if i == 0:\n",
    "                res.append(self._make_residual(block, num_blocks, planes))\n",
    "            hg.append(nn.ModuleList(res))\n",
    "        return nn.ModuleList(hg)\n",
    "\n",
    "    def _hour_glass_forward(self, n, x):\n",
    "        up1 = self.hg[n-1][0](x)\n",
    "        low1 = F.max_pool2d(x, 2, stride=2)\n",
    "        low1 = self.hg[n-1][1](low1)\n",
    "\n",
    "        if n > 1:\n",
    "            low2 = self._hour_glass_forward(n-1, low1)\n",
    "        else:\n",
    "            low2 = self.hg[n-1][3](low1)\n",
    "        low3 = self.hg[n-1][2](low2)\n",
    "        up2 = F.interpolate(low3, scale_factor=2)\n",
    "        out = up1 + up2\n",
    "        return out\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._hour_glass_forward(self.depth, x)\n",
    "\n",
    "\n",
    "class HourglassNet(nn.Module):\n",
    "    '''Hourglass model from Newell et al ECCV 2016'''\n",
    "    def __init__(self, block, num_stacks=2, num_blocks=4, num_classes=16):\n",
    "        super(HourglassNet, self).__init__()\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.num_feats = 128\n",
    "        self.num_stacks = num_stacks\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=True)\n",
    "        self.bn1 = nn.BatchNorm2d(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_residual(block, self.inplanes, 1)\n",
    "        self.layer2 = self._make_residual(block, self.inplanes, 1)\n",
    "        self.layer3 = self._make_residual(block, self.num_feats, 1)\n",
    "        self.maxpool = nn.MaxPool2d(2, stride=2)\n",
    "\n",
    "        # build hourglass modules\n",
    "        ch = self.num_feats*block.expansion\n",
    "        hg, res, fc, score, fc_, score_ = [], [], [], [], [], []\n",
    "        for i in range(num_stacks):\n",
    "            hg.append(Hourglass(block, num_blocks, self.num_feats, 4))\n",
    "            res.append(self._make_residual(block, self.num_feats, num_blocks))\n",
    "            fc.append(self._make_fc(ch, ch))\n",
    "            score.append(nn.Conv2d(ch, num_classes, kernel_size=1, bias=True))\n",
    "            if i < num_stacks-1:\n",
    "                fc_.append(nn.Conv2d(ch, ch, kernel_size=1, bias=True))\n",
    "                score_.append(nn.Conv2d(num_classes, ch, kernel_size=1, bias=True))\n",
    "        self.hg = nn.ModuleList(hg)\n",
    "        self.res = nn.ModuleList(res)\n",
    "        self.fc = nn.ModuleList(fc)\n",
    "        self.score = nn.ModuleList(score)\n",
    "        self.fc_ = nn.ModuleList(fc_)\n",
    "        self.score_ = nn.ModuleList(score_)\n",
    "\n",
    "    def _make_residual(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=True),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_fc(self, inplanes, outplanes):\n",
    "        bn = nn.BatchNorm2d(inplanes)\n",
    "        conv = nn.Conv2d(inplanes, outplanes, kernel_size=1, bias=True)\n",
    "        return nn.Sequential(\n",
    "                conv,\n",
    "                bn,\n",
    "                self.relu,\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = []\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        for i in range(self.num_stacks):\n",
    "            y = self.hg[i](x)\n",
    "            y = self.res[i](y)\n",
    "            y = self.fc[i](y)\n",
    "            score = self.score[i](y)\n",
    "            out.append(score)\n",
    "            if i < self.num_stacks-1:\n",
    "                fc_ = self.fc_[i](y)\n",
    "                score_ = self.score_[i](score)\n",
    "                x = x + fc_ + score_\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "def hg(num_stacks=1, num_blocks=1, num_classes=10):\n",
    "    model = HourglassNet(Bottleneck, num_stacks=num_stacks, num_blocks=num_blocks, num_classes=num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "\n",
    "    def __init__(self, root_dir = 'ml-imagesynthesis/captures', num_classes = 18, batch_size = 1, length=6):\n",
    "        #self.device = torch.device('cpu')\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        train_transform_list = [CropAndPad(out_size=(256, 256)),LocsToHeatmaps(out_size=(64, 64)),ToTensor(),Normalize()]\n",
    "        self.train_ds = Dataset(root_dir=root_dir, transform=transforms.Compose(train_transform_list), length=length)\n",
    "\n",
    "        self.model = hg(num_stacks=1, num_blocks=1, num_classes=self.num_classes) \n",
    "        # define loss function and optimizer\n",
    "        self.heatmap_loss = torch.nn.MSELoss()  # for Global loss\n",
    "        self.optimizer = torch.optim.RMSprop(self.model.parameters(),\n",
    "                                             lr = 2.5e-4)\n",
    "        self.train_data_loader = DataLoader(self.train_ds, batch_size=batch_size,\n",
    "                                            num_workers=8,\n",
    "                                            pin_memory=True,\n",
    "                                            shuffle=True)\n",
    "\n",
    "        self.summary_iters = []\n",
    "        self.losses = []\n",
    "        self.pcks = []\n",
    "\n",
    "    def train(self, epoch = 400):\n",
    "        self.total_step_count = 0\n",
    "        start_time = time()\n",
    "        for ep in range(1,epoch+1):\n",
    "\n",
    "            print(\"Epoch %d/%d\"%(ep,epoch))\n",
    "\n",
    "            for step, batch in enumerate(self.train_data_loader):\n",
    "                self.model.train()\n",
    "                batch = {k: v  if isinstance(v, torch.Tensor) else v for k,v in batch.items()}\n",
    "                self.optimizer.zero_grad()\n",
    "                pred_heatmap_list = self.model(batch['image'])\n",
    "                print(pred_heatmap_list[-1].shape, batch['keypoint_heatmaps'].shape)\n",
    "                loss = self.heatmap_loss(pred_heatmap_list[-1], batch['keypoint_heatmaps'])\n",
    "                loss.backward()\n",
    "                self.optimizer.step()                                          \n",
    "                \n",
    "                self.total_step_count += 1\n",
    "\n",
    "\n",
    "        checkpoint = {'model': self.model.state_dict()}\n",
    "        torch.save(checkpoint, './output/model_checkpoint.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tester(object):\n",
    "\n",
    "    def __init__(self, root_dir = 'ml-imagesynthesis/captures', num_classes = 18, batch_size = 1, length=6):\n",
    "        #self.device = torch.device('cpu')\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        test_transform_list = [CropAndPad(out_size=(256, 256)),LocsToHeatmaps(out_size=(64, 64)),ToTensor(),Normalize()]\n",
    "        self.test_ds = Dataset(root_dir=root_dir, folder=\"Test/\", transform=transforms.Compose(test_transform_list), length=length)\n",
    "\n",
    "        self.model = hg(num_stacks=1, num_blocks=1, num_classes=self.num_classes) \n",
    "        # define loss function and optimizer\n",
    "        self.test_data_loader = DataLoader(self.test_ds, batch_size=self.batch_size,\n",
    "                                           pin_memory=True,\n",
    "                                           shuffle=False)\n",
    "        self.checkpoint = torch.load('./output/model_checkpoint.pt')\n",
    "        self.model.load_state_dict(self.checkpoint['model'])\n",
    "\n",
    "\n",
    "    def test(self):\n",
    "        centers = torch.zeros([len(self.test_ds), 2], dtype=torch.float32)\n",
    "        crops = torch.zeros([len(self.test_ds), 2], dtype=torch.float32)\n",
    "        scales = torch.zeros([len(self.test_ds), 2], dtype=torch.float32)\n",
    "        predicted_heatmaps = np.zeros((len(self.test_ds), self.num_classes, 64, 64))\n",
    "        count = 0\n",
    "        \n",
    "        for i, batch in enumerate(tqdm(self.test_data_loader)):\n",
    "            self.model.eval()\n",
    "            images = batch['image'] \n",
    "            \n",
    "            centers[count:count+self.batch_size, :] = batch['center']\n",
    "            crops[count:count+self.batch_size, :] = batch['crop']\n",
    "            scales[count:count+self.batch_size, :] = batch['scale']\n",
    "            with torch.no_grad():\n",
    "                pred_heatmap_list = self.model(images)\n",
    "            pred_heatmaps = pred_heatmap_list[-1]\n",
    "            predicted_heatmaps[count:count+self.batch_size,:,:,:] = pred_heatmaps[0,:,:,:].numpy()\n",
    "            \n",
    "            count = count + self.batch_size \n",
    "            \n",
    "        np.save('./output/detections.npy', predicted_heatmaps)\n",
    "        return centers, crops, scales\n",
    "        \n",
    "    def test_net(self):\n",
    "    \n",
    "        # iterate through the test dataset\n",
    "        for i, sample in enumerate(self.test_data_loader):\n",
    "\n",
    "          # get sample data: images and ground truth keypoints\n",
    "            self.model.eval()\n",
    "            ori_images = sample['orig_image'] \n",
    "            images = sample['image'] \n",
    "            key_pts = sample['keypoints'] \n",
    "\n",
    "            with torch.no_grad():\n",
    "                pred_heatmap_list = self.model(images)\n",
    "\n",
    "            pred_heatmaps = pred_heatmap_list[-1]\n",
    "            output_pts = heatmaps_to_locs(pred_heatmaps)\n",
    "            # reshape to batch_size x 68 x 2 pts\n",
    "            #output_pts = output_pts.view(output_pts.size()[0], self.num_classes, -1)\n",
    "\n",
    "            output_pts[:,:,:-1] *= 256 / 64\n",
    "\n",
    "            # break after first image is tested\n",
    "            if i == 0:\n",
    "                return ori_images, images, output_pts[:,:,:-1], key_pts[:,:,:-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
