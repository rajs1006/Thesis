{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CfWT6uZPzMb0",
    "outputId": "4e3756e0-1c57-4f84-a6e0-5723041fe1ae"
   },
   "outputs": [],
   "source": [
    "#!unzip -q '/content/data.zip'\n",
    "#! pip install barbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T8XIqCbSlxBb"
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "import pandas as pd\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import os\n",
    "#from os import join\n",
    "from time import time\n",
    "import numpy as np  \n",
    "import cv2 \n",
    "\n",
    "from barbar import Bar\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "# %run Utils.ipynb\n",
    "# %run Visualize.ipynb\n",
    "# %run Model.ipynb\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.cm import jet\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.collections import PatchCollection\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from numpy import linalg as lin\n",
    "from shapely.geometry import Polygon as P\n",
    "\n",
    "\n",
    "os.makedirs('./output', exist_ok=True)\n",
    "\n",
    "path = \"/home/sourabh/Documents/GIT/Python/Deep-NN/PoseTracking\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "INRJbq96oqY7"
   },
   "source": [
    "--------------**Uitility**-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Aqm2jb5oN3g"
   },
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir = 'data', folder=\"Train/\" , kp_file = 'image_%05d_img', transform=None, length=5):\n",
    "        self.root_dir = os.path.join(path, root_dir, folder)\n",
    "        \n",
    "        self.key_pts_file = os.path.join(self.root_dir, kp_file)\n",
    "        self.transform = transform\n",
    "        \n",
    "        files = os.listdir(self.root_dir)\n",
    "        self.dataLen = int(len(files)/length)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataLen\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # ensure there aren't conflicting file pointers\n",
    "        \n",
    "        image = imageio.imread(os.path.join(self.root_dir, \"{}.png\".format(self.key_pts_file %idx)))\n",
    "        if(image.shape[2] == 4):\n",
    "                image = image[:,:,0:3]\n",
    "        \n",
    "        initialKPs = np.array(pd.read_csv(os.path.join(self.root_dir, \"{}-ORB.txt\".format(self.key_pts_file %idx)), header=None))\n",
    "        initialKPs = np.c_[ initialKPs, np.ones(initialKPs.shape[0]) ]\n",
    "        \n",
    "        KPs = np.array(pd.read_csv(os.path.join(self.root_dir, \"{}-GT.txt\".format(self.key_pts_file %idx)), header=None))\n",
    "        KPs = np.c_[ KPs, np.ones(KPs.shape[0]) ]\n",
    "        \n",
    "        image = Image.fromarray(image)\n",
    "        \n",
    "        bb = np.array(pd.read_csv(os.path.join(self.root_dir, \"{}-BOUND.txt\".format(self.key_pts_file %idx)), header=None)).ravel()\n",
    "        \n",
    "        item = {'image': image, 'original_image': np.asarray(image) ,'bb': bb, 'initial_keypoints' : initialKPs, 'keypoints': KPs}\n",
    "        if self.transform is not None:\n",
    "            item = self.transform(item)\n",
    "        return item\n",
    "\n",
    "#Transformations\n",
    "\n",
    "def generate_heatmap(heatmap, pt, sigma):\n",
    "    heatmap[int(pt[1])][int(pt[0])] = 1\n",
    "    heatmap = cv2.GaussianBlur(heatmap, sigma, 0)\n",
    "    am = np.amax(heatmap)\n",
    "    heatmap /= am\n",
    "    return heatmap\n",
    "\n",
    "def render_onehot_heatmap(coord, input_shape,output_shape):\n",
    "        #print(coord.shape)\n",
    "        num_kps = 18\n",
    "        batch_size = 1\n",
    "\n",
    "        x = np.reshape(coord[:,0] / input_shape[1] * output_shape[1],[-1])\n",
    "        y = np.reshape(coord[:,1] / input_shape[0] * output_shape[0],[-1])\n",
    "        x_floor = np.floor(x)\n",
    "        y_floor = np.floor(y)\n",
    "\n",
    "        x_floor = np.clip(x_floor, 0, output_shape[1] - 1)  # fix out-of-bounds x\n",
    "        y_floor = np.clip(y_floor, 0, output_shape[0] - 1)  # fix out-of-bounds y\n",
    "        #print(\"floor \", x_floor, y_floor)\n",
    "        indices_batch = np.expand_dims(\\\n",
    "                np.reshape(\\\n",
    "                np.transpose(\\\n",
    "                np.tile(\\\n",
    "                np.expand_dims(np.arange(batch_size),0)\\\n",
    "                ,[num_kps,1])\\\n",
    "                ,[1,0])\\\n",
    "                ,[-1]).astype(float),1)\n",
    "        #print(\"indices_batch\" , indices_batch.shape)\n",
    "        indices_batch = np.concatenate([indices_batch, indices_batch, indices_batch, indices_batch], axis=0)\n",
    "        indices_joint = np.expand_dims(np.tile(np.arange(num_kps),[batch_size]),1).astype(float)\n",
    "        indices_joint = np.concatenate([indices_joint, indices_joint, indices_joint, indices_joint], axis=0)\n",
    "        #print(\"indices_joint\" , indices_joint.shape)\n",
    "        indices_lt = np.concatenate([np.expand_dims(y_floor-1,1), np.expand_dims(x_floor-1,1)], axis=1)\n",
    "        indices_lb = np.concatenate([np.expand_dims(y_floor,1), np.expand_dims(x_floor-1,1)], axis=1)\n",
    "        indices_rt = np.concatenate([np.expand_dims(y_floor-1,1), np.expand_dims(x_floor,1)], axis=1)\n",
    "        indices_rb = np.concatenate([np.expand_dims(y_floor,1), np.expand_dims(x_floor,1)], axis=1)\n",
    "\n",
    "        indices = np.concatenate([indices_lt, indices_lb, indices_rt, indices_rb], axis=0)\n",
    "        #print(\"indices\" , indices.shape, np.where(indices==64))\n",
    "        indices = np.concatenate([indices_batch, indices, indices_joint], axis=1).astype(int)\n",
    "\n",
    "        prob_lt = (1 - (x - x_floor)) * (1 - (y - y_floor))\n",
    "        prob_lb = (1 - (x - x_floor)) * (y - y_floor)\n",
    "        prob_rt = (x - x_floor) * (1 - (y - y_floor))\n",
    "        prob_rb = (x - x_floor) * (y - y_floor)\n",
    "        probs = np.concatenate([prob_lt, prob_lb, prob_rt, prob_rb], axis=0)\n",
    "\n",
    "        heatmap = scatter_nd_numpy(indices, probs, (batch_size, *output_shape, num_kps))\n",
    "        normalizer = np.reshape(np.sum(heatmap,axis=(1,2)),[batch_size,1,1,num_kps])\n",
    "        normalizer = np.where(np.equal(normalizer,0),np.ones_like(normalizer),normalizer)\n",
    "        heatmap = heatmap / normalizer\n",
    "        \n",
    "        return np.squeeze(heatmap) \n",
    "    \n",
    "def scatter_nd_numpy(indices, updates, shape):\n",
    "    target = np.zeros(shape, dtype=updates.dtype)\n",
    "    indices = tuple(indices.reshape(-1, indices.shape[-1]).T)\n",
    "    updates = updates.ravel()\n",
    "    np.add.at(target, indices, updates)\n",
    "    return target\n",
    "\n",
    "def render_gaussian_heatmap(coord, output_shape, input_shape, sigma):\n",
    "        \n",
    "        x = [i for i in range(output_shape[1])]\n",
    "        y = [i for i in range(output_shape[0])]\n",
    "        xx,yy = np.meshgrid(y,x, indexing='ij')\n",
    "        xx = np.reshape(xx, (*output_shape,1))\n",
    "        yy = np.reshape(yy, (*output_shape,1))\n",
    "        \n",
    "        \n",
    "        x = np.reshape(coord[:,0],[1,1,coord.shape[0]]) / input_shape[1] * output_shape[1]\n",
    "        y = np.reshape(coord[:,1],[1,1,coord.shape[0]]) / input_shape[0] * output_shape[0]\n",
    "        \n",
    "        heatmap = np.exp(-(((xx-x)/np.float(sigma))**2)/np.float(2) -(((yy-y)/np.float(sigma))**2)/np.float(2))\n",
    "        #print(\"heatmap.shape  \", heatmap.shape)\n",
    "        return heatmap * 255.\n",
    "\n",
    "\n",
    "def heatmaps_to_locs(heatmaps, outSize = (64, 64)):\n",
    "    heatmaps = heatmaps.cpu().numpy()\n",
    "    conf = np.max(heatmaps, axis=(-2,-1))\n",
    "    locs = np.argmax(heatmaps.reshape((*heatmaps.shape[:2], -1)), axis=-1)\n",
    "    locs = np.stack(np.unravel_index(locs, outSize)[::-1], axis=-1) # reverse x,y\n",
    "    return torch.from_numpy(np.concatenate([locs, conf[..., None]], axis=-1).astype('float64'))\n",
    "\n",
    "\n",
    "class CropAndPad:\n",
    "\n",
    "    def __init__(self, out_size=(256,256)):\n",
    "        self.out_size = out_size[::-1]\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, bb = sample['image'], sample['bb']\n",
    "       # img_size = image.size\n",
    "        \n",
    "        min_x,max_y,max_x,min_y = bb[0], bb[1], bb[2] , bb[3]\n",
    "        center_x = (min_x + max_x) / 2\n",
    "        center_y = (min_y + max_y) / 2\n",
    "        width, height = max_x-min_x, max_y-min_y\n",
    "        ## Image crop works in a way (0, 0, 10, 10) but here the \n",
    "        ## image coordinates are revresed on Y-axis nd so the crop.\n",
    "        sample['image'] = image.crop(box=(min_x,min_y,max_x,max_y))\n",
    "        sample['orig_image'] = image\n",
    "        sample['center'] = np.array([center_x, center_y], dtype=np.float32)\n",
    "        sample['width'] = width\n",
    "        sample['height'] = height\n",
    "        \n",
    "        w, h= self.out_size\n",
    "        ## Crop and scale\n",
    "        sample['crop'] = np.array([min_x, min_y], dtype=np.float32)\n",
    "        sample['scale'] = np.array([w/width, h/height] , dtype=np.float32)\n",
    "        \n",
    "        if width != self.out_size[0]:\n",
    "            sample['image'] = sample['image'].resize((w, h))\n",
    "        if 'mask' in sample:\n",
    "            sample['mask'] = sample['mask'].crop(box=(min_x,min_y,max_x,max_y)).resize((w, h))\n",
    "        if 'keypoints' in sample:\n",
    "            keypoints = sample['keypoints']\n",
    "            for i in range(keypoints.shape[0]):\n",
    "                if keypoints[i,0] < min_x or keypoints[i,0] > max_x or keypoints[i,1] < min_y or keypoints[i,1] > max_y:\n",
    "                    keypoints[i,:] = [0,0,0]\n",
    "                else:\n",
    "                    keypoints[i,:2] = (keypoints[i,:2]-sample['crop'] )*sample['scale']\n",
    "        sample['keypoints'] = keypoints\n",
    "                    \n",
    "        if 'initial_keypoints' in sample:\n",
    "            initial_keypoints = sample['initial_keypoints']\n",
    "            for i in range(initial_keypoints.shape[0]):\n",
    "                if initial_keypoints[i,0] < min_x or initial_keypoints[i,0] > max_x \\\n",
    "                                or initial_keypoints[i,1] < min_y or initial_keypoints[i,1] > max_y:\n",
    "                    initial_keypoints[i,:] = [0,0,0]\n",
    "                else:\n",
    "                    initial_keypoints[i,:2] = (initial_keypoints[i,:2]-sample['crop'] )*sample['scale']\n",
    "        \n",
    "        sample['initial_keypoints'] = initial_keypoints\n",
    "        sample.pop('bb')\n",
    "        return sample\n",
    "\n",
    "# Convert keypoint locations to heatmaps\n",
    "class LocsToHeatmaps:\n",
    "\n",
    "    def __init__(self, img_size=(256,256), out_size=(64,64), sigma=1, algo : str=None):\n",
    "        self.img_size = img_size\n",
    "        self.out_size = out_size\n",
    "        self.x_scale = 1.0 * out_size[0]/img_size[0]\n",
    "        self.y_scale = 1.0 * img_size[0]/img_size[0]\n",
    "        self.sigma=sigma\n",
    "        x = np.arange(0, out_size[1], dtype=np.float)\n",
    "        y = np.arange(0, out_size[0], dtype=np.float)\n",
    "        self.yg, self.xg = np.meshgrid(y,x, indexing='ij')\n",
    "        self.algo = algo\n",
    "        \n",
    "        return\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        sigma = 7\n",
    "        gaussian_hm = np.zeros((self.out_size[0], self.out_size[1], sample['keypoints'].shape[0]))\n",
    "        if self.algo == 'PoseFix':\n",
    "            gaussian_hm = render_onehot_heatmap(sample['keypoints'], self.img_size, self.out_size)\n",
    "            #print(gaussian_hm.shape)\n",
    "            #gaussian_hm = render_gaussian_heatmap(sample['keypoints'], self.img_size, self.img_size, sigma)\n",
    "            #print(gaussian_hm.shape)\n",
    "        else:\n",
    "            for i,keypoint in enumerate(sample['keypoints']):\n",
    "                if keypoint[2] != 0:\n",
    "                    gaussian_hm[:,:,i] = generate_heatmap(gaussian_hm[:,:,i], tuple(keypoint.astype(np.int) * self.x_scale), (sigma, sigma))\n",
    "        sample['keypoint_locs'] = sample['keypoints'][:,:2]\n",
    "        sample['visible_keypoints'] = sample['keypoints'][:,2]\n",
    "        sample['keypoint_heatmaps'] = gaussian_hm\n",
    "        \n",
    "        gaussian_hm_init = np.zeros((self.img_size[0], self.img_size[1], sample['initial_keypoints'].shape[0]))\n",
    "        #print(\" gaussian_hm_init   : \", gaussian_hm_init.shape)\n",
    "        if self.algo == 'PoseFix':\n",
    "            gaussian_hm_init = render_gaussian_heatmap(sample['keypoints'], self.img_size, self.img_size, sigma)\n",
    "        else:\n",
    "            for i,initial_keypoints in enumerate(sample['initial_keypoints']):\n",
    "                if initial_keypoints[2] != 0:\n",
    "                    gaussian_hm_init[:,:,i] = generate_heatmap(gaussian_hm_init[:,:,i], tuple(initial_keypoints.astype(np.int) * self.y_scale ), \\\n",
    "                                                               (sigma, sigma))\n",
    "        sample['initial_keypoints_locs'] = sample['initial_keypoints'][:,:2]\n",
    "        sample['visible_initial_keypoints'] = sample['initial_keypoints'][:,2]\n",
    "        sample['initial_keypoints_heatmaps'] = gaussian_hm_init\n",
    "        \n",
    "        return sample\n",
    "\n",
    "# Convert numpy arrays to Tensor objects\n",
    "# Permute the image dimensions\n",
    "class ToTensor:\n",
    "\n",
    "    def __init__(self, downsample_mask=False):\n",
    "        self.tt = transforms.ToTensor()\n",
    "        self.downsample_mask=downsample_mask\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        sample['image'] = self.tt(sample['image'])\n",
    "        if 'orig_image' in sample:\n",
    "            sample['orig_image'] = self.tt(sample['orig_image'])\n",
    "        if 'mask' in sample:\n",
    "            if self.downsample_mask:\n",
    "                sample['mask'] = self.tt(sample['mask'].resize((64,64), Image.ANTIALIAS))\n",
    "            else:\n",
    "                sample['mask'] = self.tt(sample['mask'])\n",
    "        if 'in_mask' in sample:\n",
    "            sample['in_mask'] = self.tt(sample['in_mask'])\n",
    "            # sample['in_mask'] = sample['in_mask'].unsqueeze(0)\n",
    "        if 'keypoint_heatmaps' in sample:\n",
    "            sample['keypoint_heatmaps'] =\\\n",
    "                torch.from_numpy(sample['keypoint_heatmaps'].astype(np.float32).transpose(2,0,1))\n",
    "            sample['keypoint_locs'] =\\\n",
    "                torch.from_numpy(sample['keypoint_locs'].astype(np.float32))\n",
    "            sample['visible_keypoints'] =\\\n",
    "                torch.from_numpy(sample['visible_keypoints'].astype(np.float32))\n",
    "            \n",
    "        if 'initial_keypoints_heatmaps' in sample:\n",
    "            sample['initial_keypoints_heatmaps'] =\\\n",
    "                torch.from_numpy(sample['initial_keypoints_heatmaps'].astype(np.float32).transpose(2,0,1))\n",
    "            sample['initial_keypoints_locs'] =\\\n",
    "                torch.from_numpy(sample['initial_keypoints_locs'].astype(np.float32))\n",
    "            sample['visible_initial_keypoints'] =\\\n",
    "                torch.from_numpy(sample['visible_initial_keypoints'].astype(np.float32))\n",
    "            \n",
    "        return sample\n",
    "\n",
    "class Normalize:\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        sample['image'] = 2*(sample['image']-0.5)\n",
    "        if 'in_mask' in sample:\n",
    "            sample['in_mask'] = 2*(sample['in_mask']-0.5)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eN9ENKpcokAr"
   },
   "source": [
    "------------------**Visualize**------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DJEEv9hKofxA"
   },
   "outputs": [],
   "source": [
    "def show_keypoints(image, key_pts):\n",
    "    \"\"\"Show image with keypoints\"\"\"\n",
    "    plt.imshow(image)\n",
    "    plt.scatter(key_pts[:, 0], key_pts[:, 1], s=20, marker='.', c='m')\n",
    "\n",
    "def show_all_keypoints(image, predicted_key_pts, gt_pts=None, fileName = None ,plot=False):\n",
    "    \"\"\"Show image with predicted keypoints\"\"\"\n",
    "    # image is grayscale\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    \n",
    "    if plot:\n",
    "        plt.plot(predicted_key_pts[:, 0], predicted_key_pts[:, 1], c='m', label='Predicted')\n",
    "        # plot ground truth points as green pts\n",
    "        if gt_pts is not None:\n",
    "            plt.plot(gt_pts[:, 0], gt_pts[:, 1], c='g', label='True')\n",
    "    else:\n",
    "        \n",
    "        plt.scatter(predicted_key_pts[:, 0], predicted_key_pts[:, 1], s=20, marker='.', c='m')\n",
    "        # plot ground truth points as green pts\n",
    "        if gt_pts is not None:\n",
    "            plt.scatter(gt_pts[:, 0], gt_pts[:, 1], s=20, marker='.', c='g')\n",
    "    \n",
    "    if fileName is not None:\n",
    "        plt.savefig(\"./OutputKP/{}\".format(fileName))\n",
    "        \n",
    "# visualize the output\n",
    "# by default this shows a batch of 10 images\n",
    "def visualize_output(data, test_outputs, gt_pts=None ,batch_size=10, plot=False, savefig = False, algo=None):\n",
    "\n",
    "    for i in range(0, batch_size):\n",
    "        plt.figure(figsize=(20,10))\n",
    "        ax = plt.subplot(1, 1, 1)\n",
    "        test_data = data[i]\n",
    "        # un-transform the image data\n",
    "        image = test_data['image']   # get the image from it's Variable wrapper\n",
    "\n",
    "        # un-transform the predicted key_pts data\n",
    "        predicted_key_pts = test_outputs[i].data\n",
    "        predicted_key_pts = predicted_key_pts.numpy()\n",
    "        \n",
    "        # plot ground truth points for comparison, if they exist\n",
    "        ground_truth_pts = None\n",
    "        if gt_pts is not None:\n",
    "            ground_truth_pts = test_data['keypoints']\n",
    "        \n",
    "        file = '{}-Rescaled-Output{}.png'.format(i, \"\" if algo is None else algo) if savefig else None\n",
    "        # call show_all_keypoints\n",
    "        show_all_keypoints(image, predicted_key_pts, ground_truth_pts, fileName = file ,plot=plot)\n",
    "        \n",
    "        #print('RMS error for image %d is : %03f' %(i, np.sqrt(mean_squared_error(ground_truth_pts, predicted_key_pts))))\n",
    "            \n",
    "        #plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def visualize_test_output(test_images, test_outputs, gt_pts=None ,batch_size=10, plot=False, savefig = False, algo=None):\n",
    "\n",
    "    for i in range(0, batch_size):\n",
    "        plt.figure(figsize=(20,10))\n",
    "        #ax = plt.subplot(i+1, 1, i+1)\n",
    "\n",
    "        # un-transform the image data\n",
    "        image = test_images[i].data   # get the image from it's Variable wrapper\n",
    "        image = image.numpy()   # convert to numpy array from a Tensor\n",
    "        image = np.transpose(image, (1, 2, 0))   # transpose to go from torch to numpy image\n",
    "\n",
    "        # un-transform the predicted key_pts data\n",
    "        predicted_key_pts = test_outputs[i].data\n",
    "        predicted_key_pts = predicted_key_pts.numpy()\n",
    "        \n",
    "        # plot ground truth points for comparison, if they exist\n",
    "        ground_truth_pts = None\n",
    "        if gt_pts is not None:\n",
    "            ground_truth_pts = gt_pts[i]\n",
    "        \n",
    "        file = '{}-Output{}.png'.format(i, \"\" if algo is None else algo) if savefig else None\n",
    "        # call show_all_keypoints\n",
    "        show_all_keypoints(np.squeeze(image), np.squeeze(predicted_key_pts), np.squeeze(ground_truth_pts),fileName = file, plot=plot)\n",
    "        \n",
    "        #print('RMS error for image %d is : %03f' %(i, np.sqrt(mean_squared_error(ground_truth_pts, predicted_key_pts))))\n",
    "            \n",
    "        #plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def drawKeyPoints(num_to_display, dataSet):\n",
    "    \n",
    "    for i in range(num_to_display):\n",
    "\n",
    "        # define the size of images\n",
    "        fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "        plt.ion()\n",
    "        # randomly select a sample\n",
    "        rand_i = np.random.randint(0, len(dataSet))\n",
    "        sample = dataSet[rand_i]\n",
    "\n",
    "        # print the shape of the image and keypoints\n",
    "        print(i, sample['image'].shape, sample['keypoints'].shape)\n",
    "\n",
    "        ax = plt.subplot(1, num_to_display * 2, i + 1)\n",
    "        ax.set_title('ORB Sample #{}'.format(i))\n",
    "        \n",
    "        plt.imshow(sample['orb_image'])\n",
    "        \n",
    "        ax = plt.subplot(1, num_to_display * 2, i + 2)\n",
    "        ax.set_title('Sample #{}'.format(i))\n",
    "        \n",
    "        # Using the same display function, defined earlier\n",
    "        show_keypoints(sample['image'], sample['keypoints'])\n",
    "        \n",
    "\n",
    "def plot_mesh(faces, verts, img, R, t, cameraMatrix, filename = None):\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    plt.imshow(img)\n",
    "    verts_2d = np.matmul(cameraMatrix, np.matmul(R, verts.T) + t).T\n",
    "    verts_2d = verts_2d[:,:2] / verts_2d[:,2, None]\n",
    "    \n",
    "    patches = []\n",
    "    for face in faces:\n",
    "        points = [verts_2d[i_vertex-1] for i_vertex in face]\n",
    "        poly = Polygon(points, True)\n",
    "        patches.append(poly)\n",
    "        \n",
    "    p = PatchCollection(patches, cmap=matplotlib.cm.jet, alpha=0.4)\n",
    "    ax.add_collection(p)\n",
    "    \n",
    "    if fig is not None:\n",
    "        plt.savefig(\"./output/{}\".format(filename))\n",
    "        \n",
    "    plt.show()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zCScL9fJnD3w"
   },
   "source": [
    "---------------**MODEL**-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZRNn2a6_m75m"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Code is from https://github.com/bearpaw/pytorch-pose\n",
    "Hourglass network inserted in the pre-activated Resnet\n",
    "Use lr=0.01 for current version\n",
    "(c) YANG, Wei\n",
    "'''\n",
    "__all__ = ['HourglassNet', 'hg']\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 2\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=True)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=True)\n",
    "        self.bn3 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 2, kernel_size=1, bias=True)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.bn1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv1(out)\n",
    "\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        out = self.bn3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        #print(\"Bottleneck   \", out.shape)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Hourglass(nn.Module):\n",
    "    def __init__(self, block, num_blocks, planes, depth):\n",
    "        super(Hourglass, self).__init__()\n",
    "        self.depth = depth\n",
    "        self.block = block\n",
    "        self.hg = self._make_hour_glass(block, num_blocks, planes, depth)\n",
    "\n",
    "    def _make_residual(self, block, num_blocks, planes):\n",
    "        layers = []\n",
    "        for i in range(0, num_blocks):\n",
    "            layers.append(block(planes*block.expansion, planes))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_hour_glass(self, block, num_blocks, planes, depth):\n",
    "        hg = []\n",
    "        for i in range(depth):\n",
    "            res = []\n",
    "            for j in range(3):\n",
    "                res.append(self._make_residual(block, num_blocks, planes))\n",
    "            if i == 0:\n",
    "                res.append(self._make_residual(block, num_blocks, planes))\n",
    "            hg.append(nn.ModuleList(res))\n",
    "        return nn.ModuleList(hg)\n",
    "\n",
    "    def _hour_glass_forward(self, n, x):\n",
    "        up1 = self.hg[n-1][0](x)\n",
    "        low1 = F.max_pool2d(x, 2, stride=2)\n",
    "        low1 = self.hg[n-1][1](low1)\n",
    "\n",
    "        if n > 1:\n",
    "            low2 = self._hour_glass_forward(n-1, low1)\n",
    "        else:\n",
    "            low2 = self.hg[n-1][3](low1)\n",
    "        low3 = self.hg[n-1][2](low2)\n",
    "        up2 = F.interpolate(low3, scale_factor=2)\n",
    "        out = up1 + up2\n",
    "        #print(\"Hourglass   \", out.shape)\n",
    "        return out\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._hour_glass_forward(self.depth, x)\n",
    "\n",
    "\n",
    "class HourglassNet(nn.Module):\n",
    "    '''Hourglass model from Newell et al ECCV 2016'''\n",
    "    def __init__(self, block, num_stacks=2, num_blocks=4, num_classes=16, ch_input = 21):\n",
    "        super(HourglassNet, self).__init__()\n",
    "\n",
    "        self.inplanes = 256\n",
    "        self.num_feats = 256\n",
    "        self.num_stacks = num_stacks\n",
    "        self.conv1 = nn.Conv2d(ch_input, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=True)\n",
    "        self.bn1 = nn.BatchNorm2d(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_residual(block, self.inplanes, 1)\n",
    "        self.layer2 = self._make_residual(block, self.inplanes, 1)\n",
    "        self.layer3 = self._make_residual(block, self.num_feats, 1)\n",
    "        #self.layer4 = self._make_residual(block, self.num_feats, 1)\n",
    "        self.maxpool = nn.MaxPool2d(2, stride=2)\n",
    "\n",
    "        # build hourglass modules\n",
    "        ch = self.num_feats*block.expansion\n",
    "        hg, res, fc, score, fc_, score_ = [], [], [], [], [], []\n",
    "        for i in range(num_stacks):\n",
    "            hg.append(Hourglass(block, num_blocks, self.num_feats, 4))\n",
    "            res.append(self._make_residual(block, self.num_feats, num_blocks))\n",
    "            fc.append(self._make_fc(ch, ch))\n",
    "            score.append(nn.Conv2d(ch, num_classes, kernel_size=1, bias=True))\n",
    "            if i < num_stacks-1:\n",
    "                fc_.append(nn.Conv2d(ch, ch, kernel_size=1, bias=True))\n",
    "                score_.append(nn.Conv2d(num_classes, ch, kernel_size=1, bias=True))\n",
    "        self.hg = nn.ModuleList(hg)\n",
    "        self.res = nn.ModuleList(res)\n",
    "        self.fc = nn.ModuleList(fc)\n",
    "        self.score = nn.ModuleList(score)\n",
    "        self.fc_ = nn.ModuleList(fc_)\n",
    "        self.score_ = nn.ModuleList(score_)\n",
    "\n",
    "    def _make_residual(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=True),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_fc(self, inplanes, outplanes):\n",
    "        bn = nn.BatchNorm2d(inplanes)\n",
    "        conv = nn.Conv2d(inplanes, outplanes, kernel_size=1, bias=True)\n",
    "        return nn.Sequential(\n",
    "                conv,\n",
    "                bn,\n",
    "                self.relu,\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = []\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        #x = self.layer4(x)\n",
    "\n",
    "        for i in range(self.num_stacks):\n",
    "            y = self.hg[i](x)\n",
    "            y = self.res[i](y)\n",
    "            y = self.fc[i](y)\n",
    "            score = self.score[i](y)\n",
    "            out.append(score)\n",
    "            if i < self.num_stacks-1:\n",
    "                fc_ = self.fc_[i](y)\n",
    "                score_ = self.score_[i](score)\n",
    "                x = x + fc_ + score_\n",
    "        return out\n",
    "\n",
    "\n",
    "def hg(num_stacks=1, num_blocks=1, num_classes=10, ch_input=21):\n",
    "    model = HourglassNet(Bottleneck, num_stacks=num_stacks, num_blocks=num_blocks, num_classes=num_classes, ch_input = ch_input)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZRNn2a6_m75m"
   },
   "outputs": [],
   "source": [
    "class Rodrigues(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(self, inp):\n",
    "        pose = inp.detach().cpu().numpy()\n",
    "        rotm, part_jacob = cv2.Rodrigues(pose)\n",
    "        self.jacob = torch.Tensor(np.transpose(part_jacob)).contiguous()\n",
    "        rotation_matrix = torch.Tensor(rotm.ravel())\n",
    "        return rotation_matrix.view(3,3)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(self, grad_output):\n",
    "        grad_output = grad_output.view(1,-1)\n",
    "        grad_input = torch.mm(grad_output, self.jacob)\n",
    "        grad_input = grad_input.view(-1)\n",
    "        return grad_input\n",
    "\n",
    "rodrigues = Rodrigues.apply\n",
    "\n",
    "def pose_optimization(faces, vertices, image, keypoints_2d, conf, keypoints_3d, K):\n",
    "    # Send variables to GPU\n",
    "    start = time()\n",
    "    device = keypoints_2d.device\n",
    "   \n",
    "    keypoints_2d = torch.squeeze(keypoints_2d)\n",
    "    \n",
    "    K = K.to(device)\n",
    "    r = torch.rand(3, requires_grad=True, device=device) # rotation in axis-angle representation\n",
    "    t = torch.rand(3 ,requires_grad=True, device=device)\n",
    "    d = conf.sqrt()[:, None]\n",
    "    \n",
    "    # 2D keypoints in normalized coordinates\n",
    "    norm_keypoints_2d = torch.matmul(K.inverse(), \\\n",
    "                                     torch.cat((keypoints_2d, torch.ones(keypoints_2d.shape[0],1, device=device)), dim=-1).t()).t()[:,:-1]\n",
    "    # set up optimizer\n",
    "    optimizer = torch.optim.Adam([r,t], lr=1e-2)\n",
    "    # converge check\n",
    "    converged = False\n",
    "    rel_tol = 1e-7\n",
    "    loss_old = 100\n",
    "    while not converged:\n",
    "      optimizer.zero_grad()\n",
    "      # convert axis-angle to rotation matrix\n",
    "      R = rodrigues(r)\n",
    "      # 1) Compute projected keypoints based on current estimate of R and t\n",
    "      k3d = torch.matmul(R, keypoints_3d.transpose(1, 0)) + t[:, None]\n",
    "      proj_keypoints = (k3d / k3d[2])[0:2,:].transpose(1,0) \n",
    "      # 2) Compute error (based on distance between projected keypoints and detected keypoints)\n",
    "      err = torch.norm(((norm_keypoints_2d - proj_keypoints)*d)**2, 'fro')\n",
    "      # 3) Update based on error\n",
    "      err.backward()\n",
    "      optimizer.step()\n",
    "      # 4) Check for convergence\n",
    "      if abs(err.detach() - loss_old)/loss_old < rel_tol:\n",
    "        break\n",
    "      else:\n",
    "        loss_old = err.detach()    \n",
    "        \n",
    "    \n",
    "    dataGT = norm_keypoints_2d.detach().cpu().numpy().astype(float)\n",
    "    dataPnP = proj_keypoints.detach().cpu().numpy().astype(float)\n",
    "    \n",
    "    #print('torch norm ', torch.norm(((norm_keypoints_2d - proj_keypoints))**2, 'fro'))\n",
    "    reprojection_error = torch.norm(((norm_keypoints_2d - proj_keypoints))**2, 'fro')\n",
    "    ADD = lin.norm(dataGT - dataPnP)\n",
    "    ADI = np.min([lin.norm(dataGT[i] - dataPnP[i]) for i in range(0, dataGT.shape[0])])\n",
    "    ACPD = np.mean([lin.norm(dataGT[i] - dataPnP[i]) for i in range(0, dataGT.shape[0])])\n",
    "    MCPD = np.max([lin.norm(dataGT[i] - dataPnP[i]) for i in range(0, dataGT.shape[0])])\n",
    "\n",
    "    p1 = P(dataGT).buffer(0)\n",
    "    p2 = P(dataPnP).buffer(0)\n",
    "    #print(p1.is_valid, p2.is_valid)\n",
    "    IOU = np.divide(p1.intersection(p2).area, p1.union(p2).area)\n",
    "\n",
    "\n",
    "    R = rodrigues(r)\n",
    "    plt.figure()\n",
    "    plot_mesh(faces, vertices, image, R.detach().cpu().numpy(), t.detach().cpu().numpy()[:,None], K.detach().cpu().numpy(), fig='fig_{:.4f}'.format(ADD))\n",
    "    plt.show()\n",
    "    \n",
    "    return ADD, ADI, ACPD, MCPD, IOU,reprojection_error, time()-start "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZRNn2a6_m75m"
   },
   "outputs": [],
   "source": [
    "\n",
    "def pnp(faces, vertices, img, keypoints_2d, keypoints_3d, K, filename=None , flag=cv2.SOLVEPNP_ITERATIVE):\n",
    "    \n",
    "    #print(flag)\n",
    "    start = time()\n",
    "    device = keypoints_2d.device\n",
    "    \n",
    "    keypoints_3d = keypoints_3d.to(device)\n",
    "    K = K.to(device)\n",
    "    \n",
    "    keypoints_2d = torch.squeeze(keypoints_2d)\n",
    "    \n",
    "    #print('KPs', KPs.detach().cpu().numpy().astype(float).shape)\n",
    "    ret, rvecs, tvecs = cv2.solvePnP(keypoints_3d.detach().cpu().numpy().astype(float),\\\n",
    "                                     keypoints_2d.detach().cpu().numpy().astype(float),\\\n",
    "                                     K.detach().cpu().numpy().astype(float),\\\n",
    "                                     np.zeros((1,5)), flags = flag)\n",
    "    \n",
    "    r, part_jacob = cv2.Rodrigues(rvecs)\n",
    "    t = tvecs\n",
    "    \n",
    "    norm_keypoints_2d = torch.matmul(K.inverse(), torch.cat((keypoints_2d, \n",
    "                                        torch.ones(keypoints_2d.shape[0],1, device=keypoints_2d.device)), dim=-1).t()).t()[:,:-1]\n",
    "    \n",
    "    #k3d = torch.matmul(K, torch.matmul(torch.Tensor(r), torch.FloatTensor(keypoints_3d).transpose(1, 0)) + torch.Tensor(t))\n",
    "    k3d = torch.matmul(torch.Tensor(r), keypoints_3d.transpose(1, 0)) + torch.Tensor(t)\n",
    "    \n",
    "    proj_keypoints = (k3d / k3d[2])[0:2,:].transpose(1,0) \n",
    "\n",
    "    dataGT = norm_keypoints_2d.detach().cpu().numpy().astype(float)\n",
    "    dataPnP = proj_keypoints.detach().cpu().numpy().astype(float)\n",
    "    \n",
    "    reprojection_error = torch.norm(((norm_keypoints_2d - proj_keypoints))**2, 'fro')\n",
    "    ADD = lin.norm(dataGT - dataPnP)\n",
    "    ADI = np.min([lin.norm(dataGT[i] - dataPnP[i]) for i in range(0, dataGT.shape[0])])\n",
    "    ACPD = np.mean([lin.norm(dataGT[i] - dataPnP[i]) for i in range(0, dataGT.shape[0])])\n",
    "    MCPD = np.max([lin.norm(dataGT[i] - dataPnP[i]) for i in range(0, dataGT.shape[0])])\n",
    "\n",
    "    p1 = P(dataGT).buffer(0)\n",
    "    p2 = P(dataPnP).buffer(0)\n",
    "    IOU = np.divide(p1.intersection(p2).area, p1.union(p2).area)\n",
    "    \n",
    "    plt.figure(figsize=(15,10))\n",
    "    #print(fig)\n",
    "    plot_mesh(faces, vertices, img, r, t, K.detach().cpu().numpy(), filename = filename)\n",
    "    plt.show()\n",
    "    \n",
    "    return ADD, ADI, ACPD, MCPD, IOU, reprojection_error, time()-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5U2eBSDPnMj1"
   },
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "\n",
    "    def __init__(self, root_dir = 'data', num_classes = 18, batch_size = 1, length=6, algo = None):\n",
    "        self.device = torch.device('cpu')\n",
    "        #self.device = torch.cuda.current_device()\n",
    "        torch.cuda.manual_seed(123)  # Set seed\n",
    "\n",
    "        if algo == 'PoseFix':\n",
    "          ch_input=21\n",
    "        else:\n",
    "          ch_input=3\n",
    "        self.num_classes = num_classes\n",
    "        self.model = hg(num_stacks=1, num_blocks=1, num_classes=self.num_classes, ch_input=ch_input) \n",
    "\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        # define loss function and optimizer\n",
    "        self.algo = algo;\n",
    "        #print(\"self.algo  : \", self.algo)\n",
    "        if self.algo == 'PoseFix':\n",
    "            train_transform_list = [CropAndPad(out_size=(256, 256)),LocsToHeatmaps(out_size=(64,64), algo = algo),ToTensor(),Normalize()]\n",
    "            \n",
    "            self.softmax = torch.nn.Softmax(dim=1)\n",
    "            self.cross_entropy = torch.nn.CrossEntropyLoss().to(self.device)\n",
    "            self.heatmap_loss = torch.nn.L1Loss().to(self.device)\n",
    "\n",
    "            self.optimizer = torch.optim.Adam(self.model.parameters(),\n",
    "                                                 lr = 2.5e-4)\n",
    "        elif self.algo == 'SemanticKDD':\n",
    "            train_transform_list = [CropAndPad(out_size=(256, 256)),LocsToHeatmaps(out_size=(64, 64), algo = algo),ToTensor(),Normalize()]\n",
    "            \n",
    "            self.heatmap_loss = torch.nn.MSELoss().to(self.device)\n",
    "            self.optimizer = torch.optim.Adam(self.model.parameters(),\n",
    "                                                 lr = 2.5e-4)\n",
    "        else:\n",
    "            train_transform_list = [CropAndPad(out_size=(256, 256)),LocsToHeatmaps(out_size=(64, 64), algo = algo),ToTensor(),Normalize()]\n",
    "            \n",
    "            self.heatmap_loss = torch.nn.MSELoss().to(self.device)\n",
    "            self.optimizer = torch.optim.Adam(self.model.parameters(),\n",
    "                                                 lr = 2.5e-4)\n",
    "        \n",
    "        self.train_ds = Dataset(root_dir=root_dir, transform=transforms.Compose(train_transform_list), length=length)\n",
    "        self.train_data_loader = DataLoader(self.train_ds, batch_size=batch_size,\n",
    "                                            num_workers=8,\n",
    "                                            pin_memory=True,\n",
    "                                            shuffle=True)\n",
    "\n",
    "        self.summary_iters = []\n",
    "        self.losses = []\n",
    "        self.pcks = []\n",
    "\n",
    "    def train(self, epochs = 400):\n",
    "        \n",
    "        self.total_step_count = 0\n",
    "        start_time = time()\n",
    "        for epoch in range(1, epochs + 1):\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "            for step, batch in enumerate(self.train_data_loader):\n",
    "              \n",
    "                self.model.train()\n",
    "                batch = {k: v.to(self.device) if isinstance(v, torch.Tensor) else v for k,v in batch.items()}\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                # print(batch['image'].shape, batch['keypoint_heatmaps'].shape, batch['initial_keypoints_heatmaps'].shape, \\\n",
    "                #       torch.cat([batch['image'], batch['initial_keypoints_heatmaps']], 1 ).shape)\n",
    "                \n",
    "                if self.algo == 'PoseFix':\n",
    "                    pred_heatmap_list = self.model(torch.cat([batch['image'], batch['initial_keypoints_heatmaps']], 1 ).to(self.device))\n",
    "                    kp_transpose = batch['keypoint_heatmaps'].transpose(1,2).transpose(2,3)\n",
    "                    #print(kp_transpose[:,:,:, -1].shape, pred_heatmap_list[-1].long().shape)\n",
    "                    cros_entropy_loss = self.cross_entropy(pred_heatmap_list[-1], kp_transpose[:,:,:, -1].long())\n",
    "                    l1_loss = self.heatmap_loss(batch['keypoint_heatmaps'], pred_heatmap_list[-1])\n",
    "\n",
    "                    loss = cros_entropy_loss + l1_loss    \n",
    "                else:\n",
    "                    pred_heatmap_list = self.model(batch['image'].to(self.device))\n",
    "                    loss = self.heatmap_loss(batch['keypoint_heatmaps'], pred_heatmap_list[-1])\n",
    "                                                       \n",
    "                loss.backward()\n",
    "                self.optimizer.step()                                          \n",
    "                \n",
    "                self.total_step_count += 1\n",
    "                \n",
    "                # print loss statistics\n",
    "                running_loss += loss.item()\n",
    "                if step % 10 == 0:    # print every 10 batches\n",
    "                    print('Epoch: {}, Batch: {}, Total steps {} ,Avg. Loss: {}, time taken {}'.format(epoch, step+1, self.total_step_count, running_loss, time() - start_time))\n",
    "                    running_loss = 0.0\n",
    "\n",
    "        checkpoint_file = './output/model_checkpointv1.pt' if self.algo is None else './output/{}_model_checkpointv1.pt'.format(self.algo)\n",
    "        checkpoint = {'model': self.model.state_dict()}\n",
    "        print('saving model to ', checkpoint_file)\n",
    "        torch.save(checkpoint, checkpoint_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b4eCflJTnhp6"
   },
   "outputs": [],
   "source": [
    "import pywavefront\n",
    "from pywavefront import mesh\n",
    "\n",
    "class Tester(object):\n",
    "\n",
    "    def __init__(self, root_dir = 'data', num_classes = 18, batch_size = 1, length=6, algo = None):\n",
    "        self.device = torch.device('cpu')\n",
    "        #self.device = torch.cuda.current_device()\n",
    "        #torch.cuda.manual_seed(123)  # Set seed\n",
    "        \n",
    "        self.root_dir = root_dir\n",
    "        self.num_classes = num_classes\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        test_transform_list = [CropAndPad(out_size=(256, 256)),LocsToHeatmaps(out_size=(64, 64), algo = algo),ToTensor(),Normalize()]\n",
    "        self.test_ds = Dataset(root_dir=root_dir, folder=\"Test/\", transform=transforms.Compose(test_transform_list), length=length)\n",
    "\n",
    "        if algo == 'PoseFix':\n",
    "          ch_input=21\n",
    "        else:\n",
    "          ch_input=3\n",
    "\n",
    "        self.model = hg(num_stacks=1, num_blocks=1, num_classes=self.num_classes, ch_input=ch_input)\n",
    "        self.model.to(self.device)\n",
    "        # define loss function and optimizer\n",
    "        self.test_data_loader = DataLoader(self.test_ds, batch_size=self.batch_size,\n",
    "                                           pin_memory=True,\n",
    "                                           shuffle=False)\n",
    "        self.algo = algo\n",
    "        if self.algo is not None:\n",
    "            file = './output/model_checkpoint.pt' if algo is None else './output/{}-model_checkpoint.pt'.format(self.algo)\n",
    "            print('fetching model from ', file)\n",
    "        else:\n",
    "            file = './output/model_checkpoint.pt'\n",
    "            print('fetching model from ', file)\n",
    "            \n",
    "        self.checkpoint = torch.load(file)\n",
    "        self.model.load_state_dict(self.checkpoint['model'])\n",
    "\n",
    "    def test(self, flag=None):\n",
    "        \n",
    "        centers = torch.zeros([len(self.test_ds), 2], dtype=torch.float32)\n",
    "        crops = torch.zeros([len(self.test_ds), 2], dtype=torch.float32)\n",
    "        scales = torch.zeros([len(self.test_ds), 2], dtype=torch.float32)\n",
    "        predicted_heatmaps = np.zeros((len(self.test_ds), self.num_classes, 64, 64))\n",
    "        #predicted_heatmaps = np.zeros((len(self.test_ds), self.num_classes,256,256))\n",
    "        count = 0\n",
    "        \n",
    "        faces = pd.read_csv(os.path.join(path, self.root_dir, \"GroundTruth/image_groundtruth_img-faces.txt\"), header=None, sep=',').to_numpy().astype(int)\n",
    "        vertices = pd.read_csv(os.path.join(path, self.root_dir, \"GroundTruth/image_groundtruth_img-vertices.txt\"), header=None, sep=',').to_numpy().astype(float)\n",
    "        \n",
    "        point3D = pd.read_csv(os.path.join(path, self.root_dir, \"GroundTruth/3DPoints.txt\"), header=None).to_numpy().astype(float)\n",
    "        cameraMatrix = pd.read_csv(os.path.join(path, self.root_dir, \"GroundTruth/CameraMatrix.txt\"), header=None).to_numpy().astype(float)\n",
    "        #print('vertices', vertices.shape)\n",
    "        \n",
    "        ADDError = []\n",
    "        ADIError = []\n",
    "        ACPDError = []\n",
    "        MCPDError = []\n",
    "        IOUs = []\n",
    "        RPError = []\n",
    "        tpnp = []\n",
    "        \n",
    "        start_time = time()\n",
    "        errors = []\n",
    "        for i, batch in enumerate(self.test_data_loader):\n",
    "            self.model.eval()\n",
    "            images = batch['image']\n",
    "            \n",
    "            centers[count:count+self.batch_size, :] = batch['center']\n",
    "            crops[count:count+self.batch_size, :] = batch['crop']\n",
    "            scales[count:count+self.batch_size, :] = batch['scale']\n",
    "            with torch.no_grad():\n",
    "                if self.algo == 'PoseFix':  \n",
    "                  pred_heatmap_list = self.model(torch.cat([images, batch['initial_keypoints_heatmaps']], 1 ).to(self.device))\n",
    "                else:\n",
    "                  pred_heatmap_list = self.model(images.to(self.device))\n",
    "\n",
    "            pred_heatmaps = pred_heatmap_list[-1]\n",
    "            output_pts = heatmaps_to_locs(pred_heatmaps)\n",
    "            \n",
    "            output_pts = output_pts[:,:,:-1] * (256 / 64)\n",
    "            output_pts = output_pts / batch['scale'][:,:].type(torch.DoubleTensor)\n",
    "            output_pts = output_pts + batch['crop'][:,:].type(torch.DoubleTensor)\n",
    "            \n",
    "            image = batch['original_image'].data\n",
    "            image = image.numpy()   \n",
    "            image = np.squeeze(image)   # convert to numpy array from a Tensor\n",
    "            \n",
    "            if flag is not None:\n",
    "                ADD, ADI, ACPD, MCPD, IOU,reprojection_error, t = pnp(faces, vertices, image , \\\n",
    "                                                                        output_pts.type(torch.FloatTensor),\\\n",
    "                                                                        torch.FloatTensor(point3D), torch.FloatTensor(cameraMatrix),\\\n",
    "                                                                      filename = '{}_{}.png'.format(flag, i), flag=flag)\n",
    "            else:\n",
    "                ADD, ADI, ACPD, MCPD, IOU,reprojection_error, t = pose_optimization(faces, vertices, image, \\\n",
    "                                                                                        torch.squeeze(output_pts[:,:,:-1]).type(torch.FloatTensor), \\\n",
    "                                                                                        torch.squeeze(output_pts[:,:,-1]).type(torch.FloatTensor),\\\n",
    "                                                                                        torch.FloatTensor(point3D), torch.FloatTensor(cameraMatrix))\n",
    "           \n",
    "            errors.append(torch.nn.MSELoss()(batch['keypoint_heatmaps'].to(self.device), pred_heatmaps).to(self.device))\n",
    "            \n",
    "            ADDError.append(ADD)\n",
    "            ADIError.append(ADI)\n",
    "            ACPDError.append(ACPD)\n",
    "            MCPDError.append(MCPD)\n",
    "            IOUs.append(IOU)\n",
    "            RPError.append(reprojection_error.detach().cpu().numpy())\n",
    "            tpnp.append(t)\n",
    "\n",
    "            predicted_heatmaps[count:count+self.batch_size,:,:,:] = pred_heatmaps[0,:,:,:].cpu().numpy()\n",
    "            \n",
    "            count = count + self.batch_size \n",
    "    \n",
    "        \n",
    "        print('error {} , time taken {}'.format(torch.mean(torch.FloatTensor(errors)), time()-start_time))\n",
    "        print('PnP ADD, ADI, ACPD, MCPD, Mean IOU , RPError {:.4f} {:.4f} {:.4f} {:.4f} {:.6f} {:.6f}'.format(np.mean(ADDError), np.mean(ADIError), np.min(ACPDError)\\\n",
    "                                                                 , np.min(MCPDError), np.mean(IOUs), np.mean(RPError)))\n",
    "        \n",
    "        keypoint_file = './output/detectionsv1.npy' if algo is None else './output/{}-detectionsv1.npy'.format(self.algo)\n",
    "        print('Saving keypoints to ', keypoint_file)\n",
    "        np.save(keypoint_file, predicted_heatmaps)\n",
    "        \n",
    "        return centers, crops, scales\n",
    "        \n",
    "    def test_net(self):\n",
    "    \n",
    "        # iterate through the test dataset\n",
    "        for i, sample in enumerate(self.test_data_loader):\n",
    "\n",
    "          # get sample data: images and ground truth keypoints\n",
    "            self.model.eval()\n",
    "            ori_images = sample['orig_image'] \n",
    "            images = sample['image'] \n",
    "            key_pts = sample['keypoints'] \n",
    "\n",
    "            with torch.no_grad():\n",
    "                if self.algo == 'PoseFix':  \n",
    "                  pred_heatmap_list = self.model(torch.cat([images, batch['initial_keypoints_heatmaps']], 1 ).cuda())\n",
    "                else:\n",
    "                  pred_heatmap_list = self.model(images.to(self.device))\n",
    "\n",
    "            pred_heatmaps = pred_heatmap_list[-1]\n",
    "            output_pts = heatmaps_to_locs(pred_heatmaps)\n",
    "            #print('output_pts ', output_pts[:,:,:-1].size(), pred_heatmaps.size())\n",
    "            # reshape to batch_size x 68 x 2 pts\n",
    "            output_pts = output_pts.view(output_pts.size()[0], self.num_classes, -1)\n",
    "\n",
    "            output_pts[:,:,:-1] *= 256 / 64\n",
    "\n",
    "            # break after first image is tested\n",
    "            if i == 0:\n",
    "                return ori_images, images, output_pts[:,:,:-1], key_pts[:,:,:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KB5Os59qnlug"
   },
   "source": [
    "----------------**Train/Test**----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EqFYi10yC-pn"
   },
   "outputs": [],
   "source": [
    "#algo = 'PoseFix'\n",
    "algo='SemanticKDD'\n",
    "#algo = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jhJuke70nrzV"
   },
   "outputs": [],
   "source": [
    "\n",
    "trainer = Trainer(algo = algo, batch_size = 2)\n",
    "trainer.train(epochs = 300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "KQzbREmdnvw7",
    "outputId": "c080a02c-9441-4014-a162-8e3d57a1d247"
   },
   "outputs": [],
   "source": [
    "tester = Tester(root_dir='data/captures-panda', batch_size = 1, algo = algo)\n",
    "\n",
    "centers, crops, scales = tester.test(flag=0)\n",
    "\n",
    "# for t in [cv2.SOLVEPNP_ITERATIVE, cv2.SOLVEPNP_EPNP, cv2.SOLVEPNP_DLS]:\n",
    "#     print('**********',t,'****************')\n",
    "#     centers, crops, scales = tester.test(flag=t)\n",
    "    \n",
    "# centers, crops, scales = tester.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "CqaWn4Bsn0v_",
    "outputId": "7ce72478-cd81-486f-83ae-f8596e5eb666"
   },
   "outputs": [],
   "source": [
    "detectedHMs = torch.from_numpy(np.load('./output/detectionsv1.npy' if algo is None else './output/{}-detectionsv1.npy'.format(algo)))\n",
    "detectedKPs = heatmaps_to_locs(detectedHMs)\n",
    "#print(detectedKPs[:,:,:-1].size(), scales[:,None,:].size())\n",
    "KPs = detectedKPs[:,:,:-1] * (256 / 64)\n",
    "KPs = KPs / scales[:,None,:].type(torch.DoubleTensor)\n",
    "KPs = KPs + crops[:,None,:].type(torch.DoubleTensor)\n",
    "\n",
    "test_ds = Dataset(folder=\"captures-panda/Test/\", transform=None, length=5)\n",
    "\n",
    "visualize_output(test_ds, KPs, gt_pts=True, plot=True ,batch_size=10, savefig=True, algo=algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "RXRNpBRan3Ls",
    "outputId": "c0b3386a-7429-4b6d-9dd7-51dae3302e07"
   },
   "outputs": [],
   "source": [
    "oori_images,test_images, test_outputs, gt_pts = Tester(batch_size = 10, algo = algo).test_net()\n",
    "\n",
    "##print out the dimensions of the data to see if they make sense\n",
    "print(test_images.data.size())\n",
    "print(test_outputs.data.size())\n",
    "print(gt_pts.size())\n",
    "\n",
    "visualize_test_output(test_images, test_outputs, gt_pts, plot=True ,batch_size=10, savefig=True, algo=algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "PoseEstimation_Colab (2).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
